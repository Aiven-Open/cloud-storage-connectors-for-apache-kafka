/*
 * Copyright 2020 Aiven Oy
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

plugins {
    id("aiven-apache-kafka-connectors-all.java-conventions")
}

group = "io.aiven"

ext {
    // TODO: document why we stick to these versions
    kafkaVersion = "1.1.0"
    // Compatible with Kafka version:
    // https://docs.confluent.io/current/installation/versions-interoperability.html
    confluentPlatformVersion = "4.1.4"
    // Align with version used by commons
    avroConverterVersion = "7.2.2"

    slf4jVersion = "1.7.36"

    testcontainersVersion = "1.19.1"
    wireMockVersion = "2.35.0"
    mockitoVersion = "5.2.0"
}

sourceSets {
    integrationTest {
        java {
            srcDirs = ['src/integration-test/java']
        }
        resources {
            srcDirs = ['src/integration-test/resources']
        }

        compileClasspath += sourceSets.main.output + configurations.testRuntimeClasspath
        runtimeClasspath += output + compileClasspath
    }
}

idea {
    module {
        testSources.from(sourceSets.integrationTest.java.srcDirs)
        testSources.from(sourceSets.integrationTest.resources.srcDirs)
    }
}

configurations {
    integrationTestImplementation.extendsFrom testImplementation
    integrationTestRuntime.extendsFrom testRuntimeClasspath
}

dependencies {
    compileOnly "org.apache.kafka:connect-api:$kafkaVersion"
    compileOnly "org.apache.kafka:connect-runtime:$kafkaVersion"

    implementation project(":commons")

    implementation("com.google.cloud:google-cloud-storage:2.27.1") {
        exclude group: "com.google.guava", module: "guava"
    }
    // TODO: document why specific version of guava is required
    implementation "com.google.guava:guava:32.1.3-jre"

    implementation "com.github.spotbugs:spotbugs-annotations:4.8.1"
    implementation "org.slf4j:slf4j-api:$slf4jVersion"

    testImplementation 'org.junit.jupiter:junit-jupiter:5.10.0'
    testImplementation 'org.hamcrest:hamcrest:2.2'
    testImplementation 'org.assertj:assertj-core:3.24.2'
    testImplementation "org.mockito:mockito-core:$mockitoVersion"
    testImplementation "org.mockito:mockito-inline:$mockitoVersion"
    testImplementation "net.jqwik:jqwik:1.8.0"
    // is provided by "jqwik", but need this in testImplementation scope
    testImplementation "net.jqwik:jqwik-engine:1.8.1"

    testImplementation "org.apache.kafka:connect-api:$kafkaVersion"
    testImplementation "org.apache.kafka:connect-runtime:$kafkaVersion"
    testImplementation "org.apache.kafka:connect-json:$kafkaVersion"
    testImplementation "com.google.cloud:google-cloud-nio:0.127.4"

    testImplementation "org.xerial.snappy:snappy-java:1.1.10.5"
    testImplementation "com.github.luben:zstd-jni:1.5.5-5"
    testImplementation ("org.apache.parquet:parquet-tools:1.11.2") {
        exclude group: "org.slf4j", module: "slf4j-api"
    }
    testImplementation("org.apache.hadoop:hadoop-mapreduce-client-core:3.3.6") {
        exclude group: "org.apache.hadoop", module: "hadoop-yarn-client"
        exclude group: "org.apache.hadoop.thirdparty", module: "hadoop-shaded-protobuf_3_7"
        exclude group: "com.google.guava", module: "guava"
        exclude group: "commons-cli", module: "commons-cli"
        exclude group: "org.apache.commons", module: "commons-math3"
        exclude group: "org.apache.httpcomponents", module: "httpclient"
        exclude group: "commons-codec", module: "commons-codec"
        exclude group: "commons-io", module: "commons-io"
        exclude group: "commons-net", module: "commons-net"
        exclude group: "org.eclipse.jetty"
        exclude group: "org.eclipse.jetty.websocket"
        exclude group: "javax.servlet"
        exclude group: "javax.servlet.jsp"
        exclude group: "javax.activation"
        exclude group: "com.sun.jersey"
        exclude group: "log4j"
        exclude group: "org.apache.commons", module: "commons-text"
        exclude group: "org.slf4j", module: "slf4j-api"
        exclude group: "org.apache.hadoop", module: "hadoop-auth"
        exclude group: "org.apache.hadoop", module: "hadoop-yarn-api"
        exclude group: "com.google.re2j"
        exclude group: "com.google.protobuf"
        exclude group: "com.google.code.gson"
        exclude group: "com.jcraft"
        exclude group: "org.apache.curator"
        exclude group: "org.apache.zookeeper"
        exclude group: "org.apache.htrace"
        exclude group: "com.google.code.findbugs"
        exclude group: "org.apache.kerby"
        exclude group: "com.fasterxml.jackson.core"
        exclude group: "com.fasterxml.woodstox", module: "woodstox-core:5.0.3"
        exclude group: "org.apache.avro", module: "avro"
        exclude group: "org.apache.hadoop", module: "hadoop-yarn-common"
        exclude group: "com.google.inject.extensions", module: "guice-servlet"
        exclude group: "io.netty", module: "netty"
    }

    testRuntimeOnly "org.slf4j:slf4j-log4j12:$slf4jVersion"

    integrationTestImplementation "com.github.tomakehurst:wiremock-jre8:$wireMockVersion"
    integrationTestImplementation "org.testcontainers:junit-jupiter:$testcontainersVersion"
    integrationTestImplementation "org.testcontainers:kafka:$testcontainersVersion" // this is not Kafka version
    integrationTestImplementation "org.awaitility:awaitility:4.2.0"

    integrationTestImplementation "org.apache.kafka:connect-transforms:$kafkaVersion"
    // TODO: add avro-converter to ConnectRunner via plugin.path instead of on worker classpath
    integrationTestImplementation("io.confluent:kafka-connect-avro-converter:$avroConverterVersion") {
        exclude group: "org.apache.kafka", module: "kafka-clients"
    }

    // Make test utils from 'test' available in 'integration-test'
    integrationTestImplementation sourceSets.test.output
}

tasks.register('integrationTest', Test) {
    description = 'Runs the integration tests.'
    group = 'verification'
    testClassesDirs = sourceSets.integrationTest.output.classesDirs
    classpath = sourceSets.integrationTest.runtimeClasspath

    // defines testing order
    shouldRunAfter test
    // requires archive for connect runner
    dependsOn distTar

    useJUnitPlatform()

    // Run always.
    outputs.upToDateWhen { false }

    // Pass the GCS credentials path to the tests.
    if (project.hasProperty('gcsCredentialsPath')) {
        systemProperty("integration-test.gcs.credentials.path", project.findProperty('gcsCredentialsPath'))
    }
    // Pass the GCS credentials JSON to the tests.
    if (project.hasProperty('gcsCredentialsJson')) {
        systemProperty("integration-test.gcs.credentials.json", project.findProperty('gcsCredentialsJson'))
    }
    // Pass the GCS bucket name to the tests.
    systemProperty("integration-test.gcs.bucket", project.findProperty('testGcsBucket'))
    // Pass the distribution file path to the tests.
    systemProperty("integration-test.distribution.file.path", distTar.archiveFile.get().asFile.path)
    systemProperty("fake-gcs-server-version", "1.45.2")
}
pmdIntegrationTest {
    ruleSetFiles = files("${project.rootDir}/gradle-config/aiven-pmd-test-ruleset.xml")
    ruleSets = [] // Clear the default rulesets
}
spotbugsIntegrationTest {
    reports {
        html {
            stylesheet = 'fancy-hist.xsl'
        }
    }
}


processResources {
    filesMatching('gcs-connector-for-apache-kafka-version.properties') {
        expand(version: version)
    }
}

jar {
    manifest {
        attributes(
                'Version': "${project.version}"
        )
    }
}

publishing {
    publications {
        maven(MavenPublication) {
            groupId = getGroup()
            artifactId = "gcs-connector-for-apache-kafka"
            version = getVersion()

            from components.java

            pom {
                name = "Aiven's GCS Sink Connector for Apache Kafka"
                description = "Aiven's GCS Sink Connector for Apache Kafka"
                url = "https://github.com/aiven/gcs-connector-for-apache-kafka"
                organization {
                    name = "Aiven Oy"
                    url = "https://aiven.io"
                }

                licenses {
                    license {
                        name = "Apache 2.0"
                        url = "http://www.apache.org/licenses/LICENSE-2.0"
                        distribution = "repo"
                    }
                }

                developers {
                    developer {
                        id = 'aiven'
                        name = 'Aiven Opensource'
                        email = 'opensource@aiven.io'
                    }
                }

                scm {
                    connection = 'scm:git:git://github.com:aiven/gcs-connector-for-apache-kafka.git'
                    developerConnection = 'scm:git:ssh://github.com:aiven/gcs-connector-for-apache-kafka.git'
                    url = 'https://github.com/aiven/gcs-connector-for-apache-kafka'
                }
            }
        }
    }

    repositories {
        maven {
            name="sonatype"

            def releasesRepoUrl = "https://oss.sonatype.org/service/local/staging/deploy/maven2"
            def snapshotsRepoUrl = "https://oss.sonatype.org/content/repositories/snapshots"
            url = version.endsWith('SNAPSHOT') ? snapshotsRepoUrl : releasesRepoUrl

            credentials(PasswordCredentials)
        }
    }
}

signing {
    sign publishing.publications.maven
    useGpgCmd()
    // Some issue in the plugin:
    // GPG outputs already armored signatures. The plugin also does armoring for `asc` files.
    // This results in double armored signatures, i.e. garbage.
    // Override the signature type provider to use unarmored output for `asc` files, which works well with GPG.
    signatureTypes = new AbstractSignatureTypeProvider() {
        {
            BinarySignatureType binary = new BinarySignatureType() {
                @Override
                String getExtension() {
                    return "asc";
                }
            }
            register(binary);
            setDefaultType(binary.getExtension());
        }
    }
}
